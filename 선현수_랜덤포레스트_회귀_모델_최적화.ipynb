{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkgunha/Chagawa_project/blob/main/%EC%84%A0%ED%98%84%EC%88%98_%EB%9E%9C%EB%8D%A4%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8_%ED%9A%8C%EA%B7%80_%EB%AA%A8%EB%8D%B8_%EC%B5%9C%EC%A0%81%ED%99%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mjbqD8pv20cT"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w4j1Ubt122qA"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>year</th>\n",
              "      <th>price</th>\n",
              "      <th>transmission</th>\n",
              "      <th>mileage</th>\n",
              "      <th>fuelType</th>\n",
              "      <th>tax</th>\n",
              "      <th>mpg</th>\n",
              "      <th>engineSize</th>\n",
              "      <th>carMake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Octavia</td>\n",
              "      <td>2017</td>\n",
              "      <td>10550</td>\n",
              "      <td>Manual</td>\n",
              "      <td>25250</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>150.0</td>\n",
              "      <td>54.3</td>\n",
              "      <td>1.4</td>\n",
              "      <td>skoda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Citigo</td>\n",
              "      <td>2018</td>\n",
              "      <td>8200</td>\n",
              "      <td>Manual</td>\n",
              "      <td>1264</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>145.0</td>\n",
              "      <td>67.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>skoda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Octavia</td>\n",
              "      <td>2019</td>\n",
              "      <td>15650</td>\n",
              "      <td>Automatic</td>\n",
              "      <td>6825</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>145.0</td>\n",
              "      <td>67.3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>skoda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yeti Outdoor</td>\n",
              "      <td>2015</td>\n",
              "      <td>14000</td>\n",
              "      <td>Automatic</td>\n",
              "      <td>28431</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>165.0</td>\n",
              "      <td>51.4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>skoda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Superb</td>\n",
              "      <td>2019</td>\n",
              "      <td>18350</td>\n",
              "      <td>Manual</td>\n",
              "      <td>10912</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>150.0</td>\n",
              "      <td>40.9</td>\n",
              "      <td>1.5</td>\n",
              "      <td>skoda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99181</th>\n",
              "      <td>Fiesta</td>\n",
              "      <td>2016</td>\n",
              "      <td>7999</td>\n",
              "      <td>Manual</td>\n",
              "      <td>31348</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>125.0</td>\n",
              "      <td>54.3</td>\n",
              "      <td>1.2</td>\n",
              "      <td>ford</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99182</th>\n",
              "      <td>B-MAX</td>\n",
              "      <td>2017</td>\n",
              "      <td>8999</td>\n",
              "      <td>Manual</td>\n",
              "      <td>16700</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>150.0</td>\n",
              "      <td>47.1</td>\n",
              "      <td>1.4</td>\n",
              "      <td>ford</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99183</th>\n",
              "      <td>B-MAX</td>\n",
              "      <td>2014</td>\n",
              "      <td>7499</td>\n",
              "      <td>Manual</td>\n",
              "      <td>40700</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>30.0</td>\n",
              "      <td>57.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ford</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99184</th>\n",
              "      <td>Focus</td>\n",
              "      <td>2015</td>\n",
              "      <td>9999</td>\n",
              "      <td>Manual</td>\n",
              "      <td>7010</td>\n",
              "      <td>Diesel</td>\n",
              "      <td>20.0</td>\n",
              "      <td>67.3</td>\n",
              "      <td>1.6</td>\n",
              "      <td>ford</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99185</th>\n",
              "      <td>KA</td>\n",
              "      <td>2018</td>\n",
              "      <td>8299</td>\n",
              "      <td>Manual</td>\n",
              "      <td>5007</td>\n",
              "      <td>Petrol</td>\n",
              "      <td>145.0</td>\n",
              "      <td>57.7</td>\n",
              "      <td>1.2</td>\n",
              "      <td>ford</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>99186 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              model  year  price transmission  mileage fuelType    tax   mpg  \\\n",
              "0           Octavia  2017  10550       Manual    25250   Petrol  150.0  54.3   \n",
              "1            Citigo  2018   8200       Manual     1264   Petrol  145.0  67.3   \n",
              "2           Octavia  2019  15650    Automatic     6825   Diesel  145.0  67.3   \n",
              "3      Yeti Outdoor  2015  14000    Automatic    28431   Diesel  165.0  51.4   \n",
              "4            Superb  2019  18350       Manual    10912   Petrol  150.0  40.9   \n",
              "...             ...   ...    ...          ...      ...      ...    ...   ...   \n",
              "99181        Fiesta  2016   7999       Manual    31348   Petrol  125.0  54.3   \n",
              "99182         B-MAX  2017   8999       Manual    16700   Petrol  150.0  47.1   \n",
              "99183         B-MAX  2014   7499       Manual    40700   Petrol   30.0  57.7   \n",
              "99184         Focus  2015   9999       Manual     7010   Diesel   20.0  67.3   \n",
              "99185            KA  2018   8299       Manual     5007   Petrol  145.0  57.7   \n",
              "\n",
              "       engineSize carMake  \n",
              "0             1.4   skoda  \n",
              "1             1.0   skoda  \n",
              "2             2.0   skoda  \n",
              "3             2.0   skoda  \n",
              "4             1.5   skoda  \n",
              "...           ...     ...  \n",
              "99181         1.2    ford  \n",
              "99182         1.4    ford  \n",
              "99183         1.0    ford  \n",
              "99184         1.6    ford  \n",
              "99185         1.2    ford  \n",
              "\n",
              "[99186 rows x 10 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/full_2_data.csv'\n",
        "full2_data =  pd.read_csv('full_2_data.csv')\n",
        "full2_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4HpM_jx23qeJ"
      },
      "outputs": [],
      "source": [
        "#인코딩\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "lable_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "\n",
        "def Encoding(df, lable_list, onhot_list):\n",
        "  \"\"\" 범주형데이터를 숫자형으로 변경하는 함수\n",
        "  df: 변경할 데이터 프레임\n",
        "  lable_list: 라벨 인코딩\n",
        "  onhot_list: 원핫 인코딩\n",
        "  \"\"\"\n",
        "  # 라벨 인코딩\n",
        "  encoding_df=df.copy()\n",
        "  le = LabelEncoder()\n",
        "  encoding_df[lable_list] = encoding_df[lable_list].apply(le.fit_transform)\n",
        "  # 원 핫 인코딩\n",
        "  encoding_df = pd.get_dummies(encoding_df, columns=onhot_list, drop_first= True, dtype=float)\n",
        "  # drop_first: 첫번째 더미 삭제, dtype: 불리언에서 정수형으로변경\n",
        "  print(len(encoding_df.columns))\n",
        "  return encoding_df\n",
        "\n",
        "#데이터 분할\n",
        "from sklearn.model_selection import train_test_split\n",
        "def Data_split(df, price):\n",
        "  \"\"\" 데이터를 분할하는 함수\n",
        "  df: 분할할 데이터 프레임\n",
        "  price: 종속 변수명\n",
        "  출력\n",
        "  X_train: 학습데이터\n",
        "  X_test: 테스트 데이터\n",
        "  y_train: 학습데이터(실제값)\n",
        "  y_test: 테스트데이터(실제값)\n",
        "  \"\"\"\n",
        "  X = df.drop(columns=price)\n",
        "  y = df[price]\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "  print(X_train.shape, X_test.shape)\n",
        "  print(y_train.shape, y_test.shape)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "from mmap import mmap\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "\n",
        "# 로그 변환\n",
        "def Log_Trans(y_train, y_test):\n",
        "  # y값 로그변환\n",
        "  log_y_train = np.log1p(y_train)\n",
        "  log_y_test = np.log1p(y_test)\n",
        "  return log_y_train, log_y_test\n",
        "\n",
        "# sd 스케일링\n",
        "def Sd_Scaling(X_train, X_test, normalize_columns):\n",
        "  #독립 변수 표준화(standscaler방법)\n",
        "  sd_X_train = X_train.copy()\n",
        "  sd_X_test = X_test.copy()\n",
        "  standscaler = StandardScaler()\n",
        "  #train데이터 스케일링\n",
        "  sd_X_test = X_test.copy()\n",
        "  sd_X_train[normalize_columns] = standscaler.fit_transform(sd_X_train[normalize_columns])\n",
        "  #test데이터 스케일링\n",
        "  sd_X_test[normalize_columns] = standscaler.transform(sd_X_test[normalize_columns])\n",
        "  return sd_X_train, sd_X_test\n",
        "\n",
        "def MinMax_Scaling(X_train, X_test, normalize_columns):\n",
        "  #독립 변수 표준화(standscaler방법)\n",
        "  mm_X_train = X_train.copy()\n",
        "  mm_X_test = X_test.copy()\n",
        "  minmaxscaler = MinMaxScaler()\n",
        "  minmaxscaler.fit(X_train[normalize_columns])\n",
        "  #train데이터 스케일링\n",
        "  mm_X_train[normalize_columns] = minmaxscaler.transform(mm_X_train[normalize_columns])\n",
        "  #test데이터 스케일링\n",
        "  mm_X_test[normalize_columns] = minmaxscaler.transform(mm_X_test[normalize_columns])\n",
        "  return mm_X_train, mm_X_test\n",
        "\n",
        "#  표준 정규화\n",
        "def Robust_Scaling(X_train, X_test, normalize_columns):\n",
        "  #독립 변수 표준 정규화(RobustScaler방법)\n",
        "  robust_X_train = X_train.copy()\n",
        "  robust_X_test = X_test.copy()\n",
        "  robustScaler = RobustScaler()\n",
        "  #train데이터 스케일링\n",
        "  robust_X_train[normalize_columns] = robustScaler.fit_transform(robust_X_train[normalize_columns])\n",
        "  #test데이터 스케일링\n",
        "  robust_X_test[normalize_columns] = robustScaler.transform(robust_X_test[normalize_columns])\n",
        "  return robust_X_train, robust_X_test\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "def Rfr_model(x1, x2, y1, y2):\n",
        "  # 랜덤 포레스트 회귀 모델 학습\n",
        "  X_train = x1 # X_train: 학습데이터\n",
        "  X_test = x2 # X_test: 테스트 데이터\n",
        "  y_train = y1 # y_train: 학습데이터(실제값)\n",
        "  y_test = y2 # y_test: 테스트데이터(실제값)\n",
        "  \"\"\"\n",
        "  출력\n",
        "  rfr: 랜덤 포레스트 회귀 모델\n",
        "  y_train_pred: 학습데이터 예측값\n",
        "  y_test_pred: 테스트데이터 예측값\n",
        "  \"\"\"\n",
        "  # 랜덤 포레스트 회귀 모델 학습\n",
        "  rfr = RandomForestRegressor(random_state=42)\n",
        "  rfr.fit(X_train, y_train)\n",
        "  # Fitting된 모델로 예측 수행\n",
        "  y_train_pred = rfr.predict(X_train)\n",
        "  y_test_pred = rfr.predict(X_test)\n",
        "  # 랜덤 포레스트 R2-score\n",
        "  # 학습 정확도\n",
        "  train_accuarcy = rfr.score(X_train, y_train)\n",
        "  print(\"학습 정확도:\",rfr.score(X_train, y_train))\n",
        "  return rfr, y_train_pred, y_test_pred, train_accuarcy\n",
        "\n",
        "def rfr_feature_importances(rfr, X_train):\n",
        "  feature_names = X_train.columns\n",
        "  importance_df = pd.DataFrame({\n",
        "      'Feature': feature_names,\n",
        "      'Importance': rfr.feature_importances_\n",
        "  }).sort_values(by='Importance', ascending=False)\n",
        "  print(importance_df.head())\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
        "import numpy as np\n",
        "\n",
        "# 역변한 필요한 경우\n",
        "def Exp_y(log_y_test, log_y_test_pred):\n",
        "  trans_y_test = np.expm1(log_y_test) # 실제값\n",
        "  trans_y_test_pred = np.expm1(log_y_test_pred) #예상값\n",
        "  return trans_y_test, trans_y_test_pred\n",
        "\n",
        "def model_evaluation(y_test, y_test_pred, result_name ) :\n",
        "  \"\"\" 모델 평가 함수\n",
        "  trans_y_test: 데스트 데이터 역변환 실제값\n",
        "  trans_y_test_pred: 데스트데이터 역변환 예측값\n",
        "  result_name: 결과를 저장할 컬럼 이름\n",
        "  \"\"\"\n",
        "  mse = round(mean_squared_error(y_test, y_test_pred),3) # 실제 y값, 예측값\n",
        "  mae = round(mean_absolute_error(y_test, y_test_pred),3)\n",
        "  rmse = round(np.sqrt(mean_squared_error(y_test, y_test_pred)),3) # 실제 y값, 예측값\n",
        "  r2 = round(r2_score(y_test, y_test_pred),3)\n",
        "  mape = round((mean_absolute_percentage_error(y_test, y_test_pred)*100),3)\n",
        "\n",
        "  print(f\"\\nLGBM {result_name} Results\")\n",
        "  print(f\"평균 제곱 오차(MSE): {mse}\")\n",
        "  print(f\"평균 절대 오차(MAE): {mae}\")\n",
        "  print(f\"평균 제곱 오차(MSE): {rmse}\")\n",
        "  print(f\"평균 절대비율 오차(MAPE): {mape}\")\n",
        "  print(f\"결정 계수(R2): {r2}\\n\")\n",
        "\n",
        "  result_list = ['mse', 'rmse', 'mae', 'mape', 'r2']\n",
        "  result_name = str(result_name)\n",
        "  result_df = pd.DataFrame(data=[mse, rmse, mae, mape, r2],\n",
        "                           index=result_list, columns=[result_name])\n",
        "  return result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KbIwzejd24Bj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22\n",
            "(69430, 21) (29756, 21)\n",
            "(69430,) (29756,)\n",
            "학습 정확도: 0.9946784846225595\n",
            "\n",
            "LGBM rfr_Log Results\n",
            "평균 제곱 오차(MSE): 4996843.472\n",
            "평균 절대 오차(MAE): 1175.527\n",
            "평균 제곱 오차(MSE): 2235.362\n",
            "평균 절대비율 오차(MAPE): 7.268\n",
            "결정 계수(R2): 0.95\n",
            "\n",
            "학습 정확도: 0.9946797469109543\n",
            "\n",
            "LGBM rfr_mm Results\n",
            "평균 제곱 오차(MSE): 4999095.81\n",
            "평균 절대 오차(MAE): 1175.708\n",
            "평균 제곱 오차(MSE): 2235.866\n",
            "평균 절대비율 오차(MAPE): 7.269\n",
            "결정 계수(R2): 0.95\n",
            "\n",
            "학습 정확도: 0.9946811199475528\n",
            "\n",
            "LGBM rfr_sd Results\n",
            "평균 제곱 오차(MSE): 5001366.208\n",
            "평균 절대 오차(MAE): 1175.832\n",
            "평균 제곱 오차(MSE): 2236.373\n",
            "평균 절대비율 오차(MAPE): 7.269\n",
            "결정 계수(R2): 0.95\n",
            "\n",
            "학습 정확도: 0.9946802406264056\n",
            "\n",
            "LGBM rfr_robust Results\n",
            "평균 제곱 오차(MSE): 4996276.151\n",
            "평균 절대 오차(MAE): 1175.608\n",
            "평균 제곱 오차(MSE): 2235.235\n",
            "평균 절대비율 오차(MAPE): 7.268\n",
            "결정 계수(R2): 0.95\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rfr_Log</th>\n",
              "      <th>rfr_mm</th>\n",
              "      <th>rfr_sd</th>\n",
              "      <th>rfr_robust</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mse</th>\n",
              "      <td>4996843.472</td>\n",
              "      <td>4999095.810</td>\n",
              "      <td>5001366.208</td>\n",
              "      <td>4996276.151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rmse</th>\n",
              "      <td>2235.362</td>\n",
              "      <td>2235.866</td>\n",
              "      <td>2236.373</td>\n",
              "      <td>2235.235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mae</th>\n",
              "      <td>1175.527</td>\n",
              "      <td>1175.708</td>\n",
              "      <td>1175.832</td>\n",
              "      <td>1175.608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mape</th>\n",
              "      <td>7.268</td>\n",
              "      <td>7.269</td>\n",
              "      <td>7.269</td>\n",
              "      <td>7.268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>r2</th>\n",
              "      <td>0.950</td>\n",
              "      <td>0.950</td>\n",
              "      <td>0.950</td>\n",
              "      <td>0.950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         rfr_Log      rfr_mm      rfr_sd  rfr_robust\n",
              "mse  4996843.472 4999095.810 5001366.208 4996276.151\n",
              "rmse    2235.362    2235.866    2236.373    2235.235\n",
              "mae     1175.527    1175.708    1175.832    1175.608\n",
              "mape       7.268       7.269       7.269       7.268\n",
              "r2         0.950       0.950       0.950       0.950"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 연도 정규화 제외\n",
        "df = full2_data.copy()\n",
        "lable_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "normalize_columns = [\"mileage\", \"tax\", \"mpg\",\"engineSize\"] # 표준 정규화할 변수 리스트\n",
        "\n",
        "# 로그\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "log_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(X_train, X_test, log_y_train, log_y_test)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_Log = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_Log\")\n",
        "\n",
        "# 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "mm_X_train, mm_X_test = MinMax_Scaling(X_train, X_test, normalize_columns)\n",
        "mm_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(mm_X_train, mm_X_test, log_y_train, log_y_test)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_mm = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_mm\")\n",
        "\n",
        "# 표준화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "sd_X_train, sd_X_test = Sd_Scaling(X_train, X_test, normalize_columns)\n",
        "sd_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(sd_X_train, sd_X_test, log_y_train, log_y_test)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_sd = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_sd\")\n",
        "\n",
        "# 표준 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "robust_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(robust_X_train, robust_X_test, log_y_train, log_y_test)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_robust = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_robust\")\n",
        "\n",
        "result_df = pd.concat([rfr_Log, rfr_mm, rfr_sd, rfr_robust], axis=1)\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jf7Ij4at3HsJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22\n",
            "(69428, 21) (29756, 21)\n",
            "(69428,) (29756,)\n",
            "학습 정확도: 0.994512725506549\n",
            "               Feature  Importance\n",
            "6  transmission_Manual       0.327\n",
            "1                 year       0.318\n",
            "5           engineSize       0.169\n",
            "0                model       0.061\n",
            "2              mileage       0.046\n",
            "\n",
            "LGBM rfr_Log Results\n",
            "평균 제곱 오차(MSE): 4988830.713\n",
            "평균 절대 오차(MAE): 1171.032\n",
            "평균 제곱 오차(MSE): 2233.569\n",
            "평균 절대비율 오차(MAPE): 7.26\n",
            "결정 계수(R2): 0.95\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m log_y_train, log_y_test \u001b[38;5;241m=\u001b[39m Log_Trans(y_train, y_test)\n\u001b[0;32m     20\u001b[0m mm_X_train, mm_X_test \u001b[38;5;241m=\u001b[39m MinMax_Scaling(X_train, X_test, normalize_columns)\n\u001b[1;32m---> 21\u001b[0m mm_rfr, y_train_pred, y_test_pred, train_accuarcy \u001b[38;5;241m=\u001b[39m \u001b[43mRfr_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmm_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmm_X_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_y_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_y_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m rfr_feature_importances(mm_rfr, mm_X_train)\n\u001b[0;32m     23\u001b[0m trans_y_test, trans_y_test_pred \u001b[38;5;241m=\u001b[39m Exp_y(log_y_test, y_test_pred)\n",
            "Cell \u001b[1;32mIn[5], line 106\u001b[0m, in \u001b[0;36mRfr_model\u001b[1;34m(x1, x2, y1, y2)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# 랜덤 포레스트 회귀 모델 학습\u001b[39;00m\n\u001b[0;32m    105\u001b[0m rfr \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m--> 106\u001b[0m \u001b[43mrfr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Fitting된 모델로 예측 수행\u001b[39;00m\n\u001b[0;32m    108\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m rfr\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
            "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
            "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    198\u001b[0m         X,\n\u001b[0;32m    199\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    202\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    203\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Python\\Python39\\lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 연도 이상치 1980이하 제거\n",
        "df = full2_data.copy()\n",
        "df = df[df[\"year\"]>1980]\n",
        "lable_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "normalize_columns = [\"year\",\"mileage\", \"tax\", \"mpg\"] # 표준 정규화할 변수 리스트\n",
        "\n",
        "# 로그\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "log_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(X_train, X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(log_rfr, X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_Log = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_Log\")\n",
        "\n",
        "# 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "mm_X_train, mm_X_test = MinMax_Scaling(X_train, X_test, normalize_columns)\n",
        "mm_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(mm_X_train, mm_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(mm_rfr, mm_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_mm = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_mm\")\n",
        "\n",
        "# 표준화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "sd_X_train, sd_X_test = Sd_Scaling(X_train, X_test, normalize_columns)\n",
        "sd_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(sd_X_train, sd_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(sd_rfr, sd_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_sd = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_sd\")\n",
        "\n",
        "# 표준 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "robust_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(robust_X_train, robust_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(robust_rfr, robust_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_robust = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_robust\")\n",
        "\n",
        "result_df = pd.concat([rfr_Log, rfr_mm, rfr_sd, rfr_robust], axis=1)\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wHORiX_3Hp3"
      },
      "outputs": [],
      "source": [
        "# engineSize 정규화 제외\n",
        "df = full2_data.copy()\n",
        "lable_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "normalize_columns = [\"year\" , \"mileage\", \"tax\", \"mpg\"] # 표준 정규화할 변수 리스트\n",
        "\n",
        "# 로그\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "log_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(X_train, X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(log_rfr, X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_Log = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_Log\")\n",
        "\n",
        "# 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "mm_X_train, mm_X_test = MinMax_Scaling(X_train, X_test, normalize_columns)\n",
        "mm_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(mm_X_train, mm_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(mm_rfr, mm_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_mm = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_mm\")\n",
        "\n",
        "# 표준화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "sd_X_train, sd_X_test = Sd_Scaling(X_train, X_test, normalize_columns)\n",
        "sd_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(sd_X_train, sd_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(sd_rfr, sd_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_sd = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_sd\")\n",
        "\n",
        "# 표준 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "robust_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(robust_X_train, robust_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(robust_rfr, robust_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_robust = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_robust\")\n",
        "\n",
        "result_df = pd.concat([rfr_Log, rfr_mm, rfr_sd, rfr_robust], axis=1)\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAGCwJwm3Hno"
      },
      "outputs": [],
      "source": [
        "df['fuelType'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9NfhXWF3Hgb"
      },
      "outputs": [],
      "source": [
        "# 엔진 사이즈 중 0이며 엔진인경우 제외\n",
        "df = df[~((df['engineSize'] == 0) & (df['fuelType'].isin([\"Petrol\", \"Diesel\"])))]\n",
        "able_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "normalize_columns = [\"year\",\"mileage\", \"tax\", \"mpg\", \"engineSize\"] # 표준 정규화할 변수 리스트\n",
        "\n",
        "# 로그\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "log_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(X_train, X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(log_rfr, X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_Log = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_Log\")\n",
        "\n",
        "# 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "mm_X_train, mm_X_test = MinMax_Scaling(X_train, X_test, normalize_columns)\n",
        "mm_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(mm_X_train, mm_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(mm_rfr, mm_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_mm = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_mm\")\n",
        "\n",
        "# 표준화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "sd_X_train, sd_X_test = Sd_Scaling(X_train, X_test, normalize_columns)\n",
        "sd_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(sd_X_train, sd_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(sd_rfr, sd_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_sd = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_sd\")\n",
        "\n",
        "# 표준 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "robust_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(robust_X_train, robust_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(robust_rfr, robust_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_robust = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_robust\")\n",
        "\n",
        "result_df = pd.concat([rfr_base, rfr_Log, rfr_mm, rfr_sd, rfr_robust], axis=1)\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8l3KDXT3RFg"
      },
      "outputs": [],
      "source": [
        "# 엔진 사이즈 이상치, 연도 이상치, 연도 정규화X\n",
        "df = df[~((df['engineSize'] == 0) & (df['fuelType'].isin([\"Petrol\", \"Diesel\"])))]\n",
        "df = df[df[\"year\"]>1980]\n",
        "able_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "normalize_columns = [\"mileage\", \"tax\", \"mpg\", \"engineSize\"] # 표준 정규화할 변수 리스트\n",
        "\n",
        "# 로그\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "log_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(X_train, X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(log_rfr, X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_Log = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_Log\")\n",
        "\n",
        "# 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "mm_X_train, mm_X_test = MinMax_Scaling(X_train, X_test, normalize_columns)\n",
        "mm_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(mm_X_train, mm_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(mm_rfr, mm_X_train)\n",
        "log_y_test, log_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_mm = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_mm\")\n",
        "\n",
        "# 표준화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "sd_X_train, sd_X_test = Sd_Scaling(X_train, X_test, normalize_columns)\n",
        "sd_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(sd_X_train, sd_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(sd_rfr, sd_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_sd = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_sd\")\n",
        "\n",
        "# 표준 정규화\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "robust_rfr, y_train_pred, y_test_pred, train_accuarcy = Rfr_model(robust_X_train, robust_X_test, log_y_train, log_y_test)\n",
        "rfr_feature_importances(robust_rfr, robust_X_train)\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "rfr_robust = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"rfr_robust\")\n",
        "\n",
        "result_df = pd.concat([rfr_base, rfr_Log, rfr_mm, rfr_sd, rfr_robust], axis=1)\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8JyuFUk3RDJ"
      },
      "outputs": [],
      "source": [
        "pip install optuna scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyW43m_73RA2"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 데이터 로드\n",
        "df = full2_data.copy()\n",
        "df = df[~((df['engineSize'] == 0) & (df['fuelType'].isin([\"Petrol\", \"Diesel\"])))]\n",
        "df = df[df[\"year\"]>1980]\n",
        "able_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "# 데이터 스케일링\n",
        "normalize_columns = [\"mileage\", \"tax\", \"mpg\",\"engineSize\"] # 표준 정규화할 변수 리스트\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "\n",
        "\n",
        "# 목적 함수 정의\n",
        "def objective(trial):\n",
        "    # 하이퍼파라미터 범위 설정\n",
        "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300) # 생성할 트리수\n",
        "    max_depth = trial.suggest_int(\"max_depth\", 3, 20) # 최대 트리 깊이\n",
        "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20) # 노드 분할 최소 샘플 수\n",
        "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20) # 리프의 최소 샘풀 수\n",
        "\n",
        "    # 모델 생성\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # 교차 검증을 통한 평가\n",
        "    score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
        "    # MSE가 낮을수록 좋은데 이를 높을 수록 좋은 의미로 변경하기 위해 음수변환을 함.\n",
        "    return np.mean(score)\n",
        "\n",
        "# Optuna 최적화 수행\n",
        "study = optuna.create_study(direction=\"maximize\")  # score 높을 수록 좋은 방향으로 모델로 최적화\n",
        "study.optimize(objective, n_trials=50, n_jobs=-1) # n_trials는 Optuna가 하이퍼파라미터를 탐색하는 총 시도 횟수\n",
        "\n",
        "# 최적 하이퍼파라미터 출력\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "\n",
        "# 최적 모델 학습 및 평가\n",
        "best_params = study.best_params\n",
        "best_model = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Test MSE:\", mse)\n",
        "# 'n_estimators': 117, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGlN_nv03Q6k"
      },
      "outputs": [],
      "source": [
        "# 최종 모델 학습\n",
        "# 테스트 5개정도 추출해서 예측값과 실제값 확인하기\n",
        "df = full2_data.copy()\n",
        "df = df[~((df['engineSize'] == 0) & (df['fuelType'].isin([\"Petrol\", \"Diesel\"])))]\n",
        "df = df[df[\"year\"]>1980]\n",
        "\n",
        "# 하이퍼 파라미터\n",
        "n_estimators = 117\n",
        "max_depth = 19\n",
        "min_samples_split = 4\n",
        "min_samples_leaf = 2\n",
        "\n",
        "# 전처리\n",
        "lable_list = ['model']\n",
        "onhot_list = ['transmission', 'fuelType', 'carMake']\n",
        "encoding_df = Encoding(df,lable_list,onhot_list)\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = Data_split(encoding_df, 'price')\n",
        "\n",
        "# 데이터 스케일링\n",
        "normalize_columns = [\"mileage\", \"tax\", \"mpg\"] # 표준 정규화할 변수 리스트\n",
        "log_y_train, log_y_test = Log_Trans(y_train, y_test)\n",
        "robust_X_train, robust_X_test = Robust_Scaling(X_train, X_test, normalize_columns)\n",
        "\n",
        "# 모델 학습\n",
        "model = RandomForestRegressor(n_estimators = 117,\n",
        "                              max_depth = 19,\n",
        "                              min_samples_split = 4,\n",
        "                              min_samples_leaf = 2,\n",
        "                              random_state=42)\n",
        "model.fit(robust_X_train, log_y_train)\n",
        "rfr_feature_importances(model, X_train)\n",
        "train_accuarcy = model.score(robust_X_train, log_y_train)\n",
        "print(\"학습 정확도:\", model.score(robust_X_train, log_y_train))\n",
        "y_test_pred = model.predict(robust_X_test)\n",
        "\n",
        "# 예측 및 개별 트리 예측값 수집\n",
        "tree_predictions = np.array([tree.predict(robust_X_test.to_numpy()) for tree in model.estimators_])\n",
        "\"\"\"랜덤포레스트는 feature name을 사용하지만 결정트리에서는 사용하지 않아 오류발생\n",
        "robust_X_test의 feature name을 제거하기 위해 nupy 배열로 변경\"\"\"\n",
        "tree_predictions = np.expm1(tree_predictions)\n",
        "\n",
        "# 평균 및 신뢰구간 계산\n",
        "y_mean = tree_predictions.mean(axis=0)\n",
        "y_std = tree_predictions.std(axis=0)\n",
        "lower_bound = y_mean - 1.96 * y_std  # 95% 신뢰구간 하한\n",
        "upper_bound = y_mean + 1.96 * y_std  # 95% 신뢰구간 상한\n",
        "\n",
        "\n",
        "# 모델 평가\n",
        "trans_y_test, trans_y_test_pred = Exp_y(log_y_test, y_test_pred)\n",
        "Last_result = model_evaluation(trans_y_test, trans_y_test_pred, result_name=\"Last_result\")\n",
        "print(Last_result)\n",
        "\n",
        "# 신뢰구간 그래프 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(range(len(trans_y_test)), trans_y_test, color='blue', label=\"Actual\")\n",
        "plt.scatter(range(len(trans_y_test_pred)), trans_y_test_pred, color='red', label=\"Predicted\")\n",
        "plt.fill_between(range(len(trans_y_test_pred)), trans_lower_bound, trans_upper_bound, color='gray', alpha=0.3, label=\"95% CI\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.title(\"Predicted vs Actual with 95% Confidence Interval\")\n",
        "plt.show()\n",
        "\n",
        "# 테스트 데이터 일부 샘플링\n",
        "np.random.seed(42)\n",
        "sample_indices = np.random.choice(len(X_test), size=5, replace=False)\n",
        "X_sample = X_test.iloc[sample_indices]\n",
        "y_sample = y_test.iloc[sample_indices]\n",
        "# 셈플 신뢰구간 구하기\n",
        "tree_predictions = np.array([tree.predict(X_sample.to_numpy()) for tree in model.estimators_])\n",
        "tree_predictions = np.expm1(tree_predictions)\n",
        "y_sample_mean = tree_predictions.mean(axis=0)\n",
        "y_sample_std = tree_predictions.std(axis=0)\n",
        "y_sample_lower_bound = y_sample_mean - 1.96 * y_sample_std\n",
        "y_sample_upper_bound = y_sample_mean + 1.96 * y_sample_std\n",
        "\n",
        "#결과 출력\n",
        "result_df = X_sample.copy()\n",
        "encoding_df=df.copy()\n",
        "le  = LabelEncoder()\n",
        "encoding_df[lable_list] = encoding_df[lable_list].apply(le.fit_transform)\n",
        "result_df[lable_list] = result_df[lable_list].apply(le.inverse_transform)\n",
        "for category in onhot_list:\n",
        "    category_columns = [col for col in result_df.columns if col.startswith(category + \"_\")]\n",
        "    result_df[category] = result_df[category_columns].idxmax(axis=1).str.replace(category + \"_\", \"\")\n",
        "    result_df.drop(columns=category_columns, inplace=True)\n",
        "result_df[\"Actual\"] = y_sample\n",
        "result_df[\"Predicted\"] = y_sample_mean\n",
        "result_df[\"Lower Bound (95%)\"] = y_sample_lower_bound\n",
        "result_df[\"Upper Bound (95%)\"] = y_sample_upper_bound\n",
        "print(result_df)\n",
        "\n",
        "# 결과 시각화\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.errorbar(range(5), y_sample_mean,\n",
        "             yerr=1.96 * y_sample_std, fmt='o', label=\"Predicted (95% CI)\", color='red')\n",
        "plt.scatter(range(5), y_sample, color='blue', label=\"Actual\")\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.xticks([0,1,2,3,4])\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.title(\"Random Forest Regression: Prediction with 95% Confidence Interval\")\n",
        "plt.show()\n",
        "\n",
        "result_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPcy9AOJhpJQwr9Ph8EIqFP",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
